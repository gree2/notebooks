{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### hadoop ecosystem\n",
    "\n",
    "1. hadoop\n",
    "\n",
    "1. mysql\n",
    "\n",
    "1. hive\n",
    "\n",
    "1. hbase\n",
    "\n",
    "1. zookeeper\n",
    "\n",
    "1. sqoop\n",
    "\n",
    "1. Q & A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### install hadoop\n",
    "\n",
    "\\$ brew install hadoop\n",
    "\n",
    "/usr/local/Cellar/hadoop/2.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### config hadoop-env.sh\n",
    "\n",
    "\\$ pico libexec/etc/hadoop/hadoop-env.sh\n",
    "\n",
    "replace\n",
    "\n",
    "export HADOOP_OPTS=\"$HADOOP_OPTS -Djava.net.preferIPv4Stack=true\"\n",
    "\n",
    "with\n",
    "\n",
    "export HADOOP_OPTS=\"$HADOOP_OPTS -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc=\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### config mapred-site.xml\n",
    "\n",
    "\\$ pico libexec/etc/hadoop/mapred-site.xml\n",
    "\n",
    "    <configuration>\n",
    "        <property>\n",
    "            <name>mapred.job.tracker</name>\n",
    "            <value>localhost:9010</value>\n",
    "        </property>\n",
    "    </configuration>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### config hdfs-site.xml\n",
    "\n",
    "\\$ pico libexec/etc/hadoop/hdfs-site.xml\n",
    "\n",
    "    <configuration>\n",
    "        <property>\n",
    "            <name>dfs.replication</name>\n",
    "            <value>1</value>\n",
    "        </property>\n",
    "    </configuration>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### config HADOOP_HOME and alias \n",
    "\n",
    "\\$ pico ~/.bash_profile\n",
    "\n",
    "export HADOOP_HOME=/usr/local/Cellar/hadoop/2.7.0\n",
    "\n",
    "alias hstart=\"/usr/local/Cellar/hadoop/2.7.0/sbin/start-dfs.sh;/usr/local/Cellar/hadoop/2.7.0/sbin/start-yarn.sh\"\n",
    "\n",
    "alias hstop=\"/usr/local/Cellar/hadoop/2.7.0/sbin/stop-yarn.sh;/usr/local/Cellar/hadoop/2.7.0/sbin/stop-dfs.sh\"\n",
    "\n",
    "\\$ source ~/.bash_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### config ssh\n",
    "\n",
    "generate rsa keys\n",
    "\n",
    "\\$ ssh-keygen -t rsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`enable remote login`\n",
    "\n",
    "system preferences -> sharing -> remote login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`authorize ssh keys`\n",
    "\n",
    "$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`login via ssh`\n",
    "\n",
    "$ ssh localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### format start stop\n",
    "\n",
    "\\$ hdfs namenode -format\n",
    "\n",
    "\\$ hstart\n",
    "\n",
    "\\$ jps\n",
    "\n",
    "\\$ hadoop jar path/to/hadoop-examples.jar pi 10 100\n",
    "\n",
    "\\$ hdfs dfs -mkdir -p /user/hqlgree2\n",
    "\n",
    "\\$ hdfs dfs -put book.txt /user/hqlgree2/\n",
    "\n",
    "\\$ hstop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### install mysql\n",
    "\n",
    "\\$ brew install mysql\n",
    "\n",
    "start mysql\n",
    "\n",
    "\\$ mysql.server start\n",
    "\n",
    "stop mysql\n",
    "\n",
    "\\$ mysql.server stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### install hive\n",
    "\n",
    "\\$ brew install hive\n",
    "\n",
    "/usr/local/Cellar/hive/1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### config ~/.bash_profile\n",
    "\n",
    "\\$ pico ~/.bash_profile\n",
    "\n",
    "export HIVE_HOME=/usr/local/Cellar/hive/1.1.0/libexec\n",
    "\n",
    "export HCAT_HOME=/usr/local/Cellar/hive/1.1.0/libexec/hcatalog\n",
    "\n",
    "\\$ source ~/.bash_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config mysql connector\n",
    "\n",
    "\\$ curl -L 'http://www.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.22.tar.gz/from/http://mysql.he.net/' | tar xz\n",
    "\n",
    "\\$ cd mysql-connector-java-5.1.22\n",
    "\n",
    "\\$ sudo cp mysql-connector-java-5.1.22-bin.jar /usr/local/Cellar/hive/1.1.0/libexec/lib/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### config metastore\n",
    "\n",
    "\\$ mysql -u root\n",
    "\n",
    "mysql> create database metastore;\n",
    "\n",
    "mysql> use metastore;\n",
    "\n",
    "mysql> create use 'hiveuser'@'localhost' identified by 'password';\n",
    "\n",
    "mysql> grant select, insert, update, delete, alter, create, index on metastore.* to 'hiveuser';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### config hive-site.xml\n",
    "\n",
    "\\$ cd libexec/conf\n",
    "\n",
    "\\$ cp hive-default.xml.template hive-site.xml\n",
    "\n",
    "    <property>\n",
    "        <name>javax.jdo.option.ConnectionURL</name>\n",
    "        <value>jdbc:mysql://localhost/metastore</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>javax.jdo.option.ConnectionDriverName</name>\n",
    "        <value>com.mysql.jdbc.Driver</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>javax.jdo.option.ConnectionUserName</name>\n",
    "        <value>hiveuser</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>javax.jdo.option.ConnectionPassword</name>\n",
    "        <value>password</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>datanucleus.fixedDatastore</name>\n",
    "        <value>false</value>\n",
    "    </property>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### config hive-site.xml\n",
    "\n",
    "replace\n",
    "    \n",
    "    ${system:java.io.tmpdir}/${system:user.name} => /tmp/mydir\n",
    "    \n",
    "with\n",
    "\n",
    "    ${system:java.io.tmpdir}/${hive.session.id} => /usr/local/Cellar/hive/1.0.0/libexec/iotmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### test hive\n",
    "\n",
    "\\$ hive\n",
    "\n",
    "hive> show tables;\n",
    "\n",
    "hive> create table temp_table temp_col string;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### troubleshooting\n",
    "\n",
    "\\$ mysql -u root\n",
    "\n",
    "mysql> set global binlog_format = 'ROW';\n",
    "\n",
    "\\$ hive -hiveconf hive.root.logger=INFO,console\n",
    "\n",
    "read raw hive log located at /tmp/hqlgree2/hive.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### install hbase\n",
    "\n",
    "\\$ brew install hbase\n",
    "\n",
    "/usr/local/Cellar/hbase/1.0.1\n",
    "\n",
    "if you got 404\n",
    "\n",
    "run brew update first\n",
    "\n",
    "\\$ brew update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### install zookeeper\n",
    "\n",
    "\\$ brew install zookeeper\n",
    "\n",
    "/usr/local/Cellar/zookeeper/3.4.6_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### config zookeeper\n",
    "\n",
    "\\$ mkdir /usr/local/zookeeper/data\n",
    "\n",
    "\\$ chown -R host1 /usr/local/zookeeper\n",
    "\n",
    "\\$ pico zoo.cfg\n",
    "\n",
    "tickTime=2000\n",
    "\n",
    "initLimit=10\n",
    "\n",
    "syncLimit=5\n",
    "\n",
    "dataDir=/usr/local/zookeeper/data\n",
    "\n",
    "clientPort=2181\n",
    "\n",
    "\\$ pico ~/.bash_profile\n",
    "\n",
    "export ZOOKEEPER_HOME=\"/usr/local/Cellar/zookeeper/3.4.6_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### start, status, client demo, stop\n",
    "\n",
    "\\$ zkServer.sh start\n",
    "\n",
    "\\$ zkServer.sh status\n",
    "\n",
    "\\$ zkCli.sh -server localhost:2181\n",
    "\n",
    "[zk:...] ls\n",
    "\n",
    "[zk:...] create /my_app /some_data\n",
    "\n",
    "[zk:...] get /my_app\n",
    "\n",
    "[zk:...] set /my_app /new_data\n",
    "\n",
    "[zk:...] delete /my_app\n",
    "\n",
    "\\$ skServer.sh stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### config zookeeper - 3 nodes cluster\n",
    "\n",
    "<pre>\n",
    "+-------+   +-------+   +-------+\n",
    "|       |   |       |   |       |\n",
    "| host1 |   | host2 |   | host3 |\n",
    "|       |   |       |   |       |\n",
    "+-------+   +-------+   +-------+\n",
    "</pre>\n",
    "\n",
    "after configuration\n",
    "\n",
    "login all these 3 boxes\n",
    "\n",
    "start\n",
    "\n",
    "\\$ zkServer.sh start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### config zookeeper - 3 nodes cluster zoo.cfg\n",
    "\n",
    "\\$ pico zoo.cfg\n",
    "\n",
    "tickTime=2000\n",
    "\n",
    "initLimit=10\n",
    "\n",
    "syncLimit=5\n",
    "\n",
    "dataDir=/usr/local/zookeeper/data\n",
    "\n",
    "clientPort=2181\n",
    "\n",
    "server.1=host1:20010:20011\n",
    "\n",
    "server.2=host2:20010:20011\n",
    "\n",
    "server.3=host2:20010:20011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### config zookeeper - 3 nodes cluster\n",
    "\n",
    "\\$ scp zoo.cfg hqlgree2@host1:/usr/local/Cellar/zookeeper/3.4.6_1/\n",
    "\n",
    "\\$ scp zoo.cfg hqlgree2@host2:/usr/local/Cellar/zookeeper/3.4.6_1/\n",
    "\n",
    "\\$ scp zoo.cfg hqlgree2@host3:/usr/local/Cellar/zookeeper/3.4.6_1/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\$ echo 1 myid\n",
    "\n",
    "\\$ scp myid hqlgree2@host1:/usr/local/zookeeper/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\$ echo 2 myid\n",
    "\n",
    "\\$ scp myid hqlgree2@host2:/usr/local/zookeeper/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\$ echo 3 myid\n",
    "\n",
    "\\$ scp myid hqlgree2@host3:/usr/local/zookeeper/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### install sqoop\n",
    "\n",
    "\\$ brew install sqoop\n",
    "\n",
    "/usr/local/Cellar/sqoop/1.4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### five minutes demo\n",
    "\n",
    "\\$ sqoop2-shell\n",
    "\n",
    "sqoop:000> set server --host localhost --port 12000 --webapp sqoop\n",
    "\n",
    "sqoop:000> show version --all\n",
    "\n",
    "sqoop:000> show connector\n",
    "\n",
    "sqoop:000> create link -c 2 # generic jdbc connector\n",
    "\n",
    "sqoop:000> create link -c 1 # hdfs connector\n",
    "\n",
    "sqoop:000> show link --all\n",
    "\n",
    "sqoop:000> create job -f 1 -t 2\n",
    "\n",
    "sqoop:000> start job -j 1\n",
    "\n",
    "sqoop:000> status job -j 1\n",
    "\n",
    "sqoop:000> start job -j 1 -s\n",
    "\n",
    "sqoop:000> stop job -j 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### mysql hdfs demo - create database and table\n",
    "\n",
    "$ mysql -u root -p\n",
    "\n",
    "mysql> create database sqoop;\n",
    "\n",
    "mysql> use sqoop;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "mysql> create table employee(\n",
    "\n",
    "->  emp_id int not null auto_increment,\n",
    "\n",
    "->  emp_name  varchar(32) not null,\n",
    "\n",
    "->  emp_title varchar(32) not null,\n",
    "\n",
    "->  primary key ( emp_id )\n",
    "\n",
    "->);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### mysql hdfs demo - test data\n",
    "\n",
    "mysql> insert into employee values (1, 'name1', 'dev'), (2, 'name2', 'pm'),\n",
    "\n",
    "-> (3, 'name3', 'qa'), (4, 'name4', 'test'), (5, 'name5', 'dev');\n",
    "\n",
    "Query OK, 5 rows affected (0.00 sec)\n",
    "\n",
    "Records: 5  Duplicates: 0  Warnings: 0\n",
    "\n",
    "mysql> select * from employee;\n",
    "\n",
    "<pre>\n",
    "+--------+----------+-----------+\n",
    "| emp_id | emp_name | emp_title |\n",
    "+--------+----------+-----------+\n",
    "|      1 | name1    | dev       |\n",
    "|      2 | name2    | pm        |\n",
    "|      3 | name3    | qa        |\n",
    "|      4 | name4    | test      |\n",
    "|      5 | name5    | dev       |\n",
    "+--------+----------+-----------+\n",
    "</pre>\n",
    "\n",
    "5 rows in set (0.00 sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### mysql hdfs demo - import\n",
    "\n",
    "\\$ sqoop import --connect jdbc:mysql://localhost/sqoop \\\n",
    "\n",
    "--username sqoop --password sqoop --table employee \\\n",
    "\n",
    "--target-dir /usr/hqlgree2/sqoopdata/employee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\$ sqoop import --connect jdbc:mysql://localhost/sqoop \\\n",
    "\n",
    "--username sqoop --password sqoop --table employee \\\n",
    "\n",
    "--target-dir sqoopdata/employee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\$ sqoop import --connect jdbc:mysql://localhost/sqoop \\\n",
    "\n",
    "--username sqoop --password sqoop --table employee \\\n",
    "\n",
    "--warehouse-dir sqoopdata -m 1 \\\n",
    "\n",
    "--check-column emp_id \\\n",
    "\n",
    "--incremental append \\\n",
    "\n",
    "--last-value 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### mysql hdfs demo - export\n",
    "\n",
    "\\$ sqoop export --connect jdbc:mysql://localhost/test \\\n",
    "\n",
    "--username sqoop -P --table employee -m 1 \\\n",
    "\n",
    "--export-dir '/usr/hqlgree2/sqoopdata/employee/part-m-00000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\$ sqoop --options-file export.txt --table employee \\\n",
    "\n",
    "--export-dir '/usr/hqlgree2/sqoopdata/employee/part-m-00001' \\\n",
    "\n",
    "--update-key emp_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### sqlserver hdfs demo - config sqljdbc\n",
    "\n",
    "\\$ curl -L 'http://download.microsoft.com/download/0/2/A/02AAE597-3865-456C-AE7F-613F99F850A8/sqljdbc_4.0.2206.100_enu.tar.gz' | tar xz\n",
    "\n",
    "\\$ cd sqljdbc_4.0/enu\n",
    "\n",
    "\\$ cp sqljdbc4.jar /usr/local/Cellar/sqoop/1.4.5/libexec/lib/\n",
    "\n",
    "\\$ hdfs dfs -put sqljdbc4.jar /usr/local/Cellar/sqoop/1.4.5/libexec/lib/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### sqlserver hdfs demo - codegen\n",
    "\n",
    "\\$ sqoop codegen --connect 'jdbc:sqlserver://192.168.100.100;database=sqoop;username=sa;password=as' --table employee\n",
    "\n",
    "INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hqlgree2/compile/38c5c07622a71bc6695d397b2ad36e40/employee.jar\n",
    "\n",
    "\\$ hdfs dfs -mkdir /tmp/sqoop-hqlgree2/compile/38c5c07622a71bc6695d397b2ad36e40/\n",
    "\n",
    "\\$ hdfs dfs -put /tmp/sqoop-hqlgree2/compile/38c5c07622a71bc6695d397b2ad36e40/* \\\n",
    "\n",
    "/tmp/sqoop-hqlgree2/compile/38c5c07622a71bc6695d397b2ad36e40/\n",
    "\n",
    "\\$ hdfs dfs -rm -r /user/hqlgree2/mssql/employee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### sqlserver demo - import.mssql\n",
    "\n",
    "\\$ pico import.mssql\n",
    "\n",
    "import\n",
    "\n",
    "-libjars\n",
    "\n",
    "/tmp/sqoop-hqlgree2/compile/38c5c07622a71bc6695d397b2ad36e40/employee.jar\n",
    "\n",
    "--connect\n",
    "\n",
    "'jdbc:sqlserver://192.168.100.100;database=sqoop;username=sa;password=as'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### sqlserver hdfs demo - import export\n",
    "\n",
    "\\$ sqoop --options-file mssql.options --table employee --target-dir mssql/employee\n",
    "\n",
    "\n",
    "\\$ sqoop export --connect jdbc:sqlserver://192.168.100.100:1433;database=sqoop \\\n",
    "\n",
    "--username sa --password as --table movie \\\n",
    "\n",
    "--export-dir /user/hqlgree2/sqoopdata/employee/part-m-00000 \\\n",
    "\n",
    "--import-fields-terminated-by '\\t'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thanks\n",
    "\n",
    "Q & A"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
